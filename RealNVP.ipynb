{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RealNVP (Real Non-Volume Preserving) Flows"
      ],
      "metadata": {
        "id": "V5zjZ8aAXDNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "kSP_DCj7itQp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "HSSB3rYwXA76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0qvGqdnCXAl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "from sklearn import datasets\n",
        "\n",
        "class Digits(Dataset):\n",
        "  '''Digits in lower resolution'''\n",
        "  def __init__(self, mode='train', transforms=None):\n",
        "    digits = datasets.load_digits()\n",
        "    if mode == 'train':\n",
        "      self.data = digits.data[:1000].astype(np.float32)\n",
        "    elif mode == 'val':\n",
        "      self.data = digits.data[1000:1350].astype(np.float32)\n",
        "    else:\n",
        "      self.data = digits.data[1350:].astype(np.float32)\n",
        "    \n",
        "    self.transforms = transforms\n",
        "    \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.data[idx]\n",
        "    if self.transforms:\n",
        "      sample = self.transforms(sample)\n",
        "    return sample\n",
        "\n",
        "# Visualize the data\n",
        "d = Digits('train')\n",
        "for i in range(16):\n",
        "  plt.subplot(4, 4, i+1)\n",
        "  plt.imshow(d[i].reshape(8, 8), cmap='gray')\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "Axp3zeRRhMeg",
        "outputId": "64bd2d8f-629a-4687-c973-436bfd4111f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "pFd_E_mWXOO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP(nn.Module):\n",
        "  '''\n",
        "  Args:\n",
        "  ----\n",
        "    nets           [nn.Sequential]: scale network\n",
        "    nett           [nn.Sequential]: translation network\n",
        "    num_flows      [int]: number of flows\n",
        "    prior          [torch.distribution]: distribution z comes from\n",
        "    D              [int]: dimension of the data\n",
        "    dequantization [bool]: discrete to continous transformation signal \n",
        "  '''\n",
        "  def __init__(self, nets, nett, num_flows, prior, D=2, dequantization=True):\n",
        "    super(RealNVP, self).__init__()\n",
        "    \n",
        "    self.dequantization = dequantization \n",
        "    self.prior = prior\n",
        "\n",
        "    self.t = torch.nn.ModuleList([nett() for _ in range(num_flows)])\n",
        "    self.s = torch.nn.ModuleList([nets() for _ in range(num_flows)])\n",
        "    self.num_flows = num_flows\n",
        "\n",
        "    self.D = D\n",
        "  \n",
        "  def coupling(self, x, index, forward=True):\n",
        "    '''\n",
        "    Args:\n",
        "    ----\n",
        "      x       [Tensor]: data of shape [batch, resolution]\n",
        "      index   [int]:    indicator of the current flow indicator\n",
        "      forward [bool]:   indicator of forward propagation (x to z) or inverse propagation (z to x)\n",
        "    '''\n",
        "    # Partition x\n",
        "    (xa, xb) = torch.chunk(x, 2, 1)\n",
        "\n",
        "    # Scale and Translation\n",
        "    s = self.s[index](xa)\n",
        "    t = self.t[index](xa)\n",
        "\n",
        "    # Forward:  x to y\n",
        "    if forward:\n",
        "      # yb = f^{-1}(x)\n",
        "      yb = (xb - t) * torch.exp(-s)\n",
        "    \n",
        "    # Inverse:  y to x\n",
        "    else: \n",
        "      # xb = f(y)\n",
        "      yb = torch.exp(s) * xb + t\n",
        "\n",
        "    return torch.cat((xa, yb), 1), s\n",
        "\n",
        "  def permute(self, x):\n",
        "    '''\n",
        "    Args:\n",
        "    ----\n",
        "    x [Tensor]: output of coupling layer\n",
        "    '''\n",
        "    return x.flip(1)\n",
        "  \n",
        "  def f(self, x):\n",
        "    '''\n",
        "    Definition:\n",
        "    -----------\n",
        "    Full forward propagation x to z: Coupling Layer + Permutation Layer\n",
        "    \n",
        "    Arg:\n",
        "    ----\n",
        "      x [Tensor]: data of shape [batch, resolution]\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "      z, log_det_J: latent vector and negative log determinant of Jacobian\n",
        "    '''\n",
        "    # Initialize log Jacobian determinant and z\n",
        "    log_det_J, z = x.new_zeros(x.shape[0]), x\n",
        "    for i in range(self.num_flows):\n",
        "      z, s = self.coupling(z, i, forward=True)\n",
        "      z = self.permute(z)\n",
        "      log_det_J = log_det_J - s.sum(dim=1)\n",
        "    \n",
        "    return z, log_det_J\n",
        "\n",
        "  def f_inv(self, z):\n",
        "    '''\n",
        "    Definition:\n",
        "    -----------\n",
        "    Full inverse propagation z to x\n",
        "\n",
        "    Arg:\n",
        "    ----\n",
        "      z [Tensor]: latent vector\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "      x [Tensor]: sample feature map\n",
        "    '''\n",
        "    # Initialize output feature map x\n",
        "    x = z\n",
        "    for i in reversed(range(self.num_flows)):\n",
        "      x = self.permute(x)\n",
        "      x, _ = self.coupling(x, i, forward=False)\n",
        "    \n",
        "    return x\n",
        "\n",
        "  def forward(self, x, reduction='avg'):\n",
        "    z, log_det_J = self.f(x)\n",
        "    if reduction == 'sum':\n",
        "      return -(self.prior.log_prob(z) + log_det_J).sum()\n",
        "    else:\n",
        "      return -(self.prior.log_prob(z) + log_det_J).mean()\n",
        "    \n",
        "  def sample(self, batch_size):\n",
        "    z = self.prior.sample((batch_size, self.D))\n",
        "    z = z[:, 0, :]\n",
        "    x = self.f_inv(z)\n",
        "    return x.view(-1, self.D)\n"
      ],
      "metadata": {
        "id": "0pIoluSOlA_U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxilary Functions: Training, Evaluation, Plotting"
      ],
      "metadata": {
        "id": "YVd8Kw-rWlHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
        "  if model_best is None:\n",
        "    # Load the best performing model\n",
        "    model_best = torch.load(name + '.model')\n",
        "  \n",
        "  # Evaluation mode\n",
        "  model_best.eval()\n",
        "\n",
        "  # Initialize loss and number of number of data points\n",
        "  loss, N = 0.0, 0\n",
        "\n",
        "  for batch_idx, test_batch in enumerate(test_loader):\n",
        "    if hasattr(model_best, 'dequantization'):\n",
        "      if model_best.dequantization:\n",
        "        test_batch = test_batch + (1 - torch.rand(test_batch.shape))/2\n",
        "    \n",
        "    loss_t = model_best.forward(test_batch, reduction='sum')\n",
        "    loss = loss + loss_t.item()\n",
        "    N = N + test_batch.shape[0]\n",
        "  \n",
        "  loss = loss / N\n",
        "\n",
        "  if epoch is None:\n",
        "    print(f'Final Loss: nll = {loss}')\n",
        "  else:\n",
        "    print(f'Epoch: {epoch}, val nll = {loss}')\n",
        "  \n",
        "  return loss"
      ],
      "metadata": {
        "id": "8spzZ8xdXqJX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def samples_real(name, test_loader):\n",
        "  num_x = 4\n",
        "  num_y = 4\n",
        "  x = next(iter(test_loader)).detach().numpy()\n",
        "\n",
        "  fig, ax = plt.subplots(num_x, num_y)\n",
        "  for i, ax in enumerate(ax.flatten()):\n",
        "    img = np.reshape(x[i], (8, 8))\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.axis('off')\n",
        "  \n",
        "  plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "bsnWhWmLcKwB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def samples_generated(name, data_loader, extra_name=''):\n",
        "  # Get data\n",
        "  x = next(iter(data_loader)).detach().numpy()\n",
        "\n",
        "  # Get best model\n",
        "  model_best = torch.load(name+'.model')\n",
        "  model_best.eval()\n",
        "\n",
        "  # Generation\n",
        "  num_x = 4\n",
        "  num_y = 4\n",
        "  x = model_best.sample(num_x * num_y)\n",
        "  x = x.detach().numpy()\n",
        "\n",
        "  # Visualize\n",
        "  fig, ax = plt.subplots(num_x, num_y)\n",
        "  for i, ax in enumerate(ax.flatten()):\n",
        "    img = np.reshape(x[i], (8, 8))\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.axis('off')\n",
        "  \n",
        "  # Save\n",
        "  plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
        "  plt.close()\n"
      ],
      "metadata": {
        "id": "FiM9LvYJc3w0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curve(name, nll_val):\n",
        "  plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('nll')\n",
        "  plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "i89BjwUPeJpW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
        "  # Initialize\n",
        "  nll_val = []\n",
        "  best_nll = float('inf')\n",
        "  patience = 0\n",
        "\n",
        "  # Training Loop\n",
        "  for e in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, batch in enumerate(training_loader):\n",
        "      if hasattr(model, 'dequantization'):\n",
        "        if model.dequantization:\n",
        "          batch = batch + (1. - torch.rand(batch.shape))/2\n",
        "      \n",
        "      loss = model.forward(batch)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "    \n",
        "    # Validation\n",
        "    loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
        "    nll_val.append(loss_val)\n",
        "\n",
        "    if e == 0:\n",
        "      print('Saved!')\n",
        "      torch.save(model, name + '.model')\n",
        "      best_nll = loss_val\n",
        "    else:\n",
        "      if loss_val < best_nll:\n",
        "        print('Saved!')\n",
        "        torch.save(model, name + '.model')\n",
        "        best_nll = loss_val\n",
        "        patience = 0\n",
        "\n",
        "        samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
        "      else:\n",
        "        patience = patience + 1\n",
        "    \n",
        "    if patience > max_patience:\n",
        "      break\n",
        "  \n",
        "  nll_val = np.asarray(nll_val)\n",
        "  return nll_val"
      ],
      "metadata": {
        "id": "Yr9iJ0SrejO0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deneme = torch.rand(10000)\n",
        "deneme.min(), deneme.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ymOLxQPZPc-",
        "outputId": "05013d3a-8ca7-4dfc-fe60-3a0b5c4ca467"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.8413e-06), tensor(0.9997))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deneme = deneme + (1. - torch.rand(deneme.shape))/2.\n",
        "deneme.min(), deneme.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTIyr-cUZV0G",
        "outputId": "88c51c39-70fb-4cbf-ec4a-700b508490e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0047), tensor(1.4873))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "XibazJyiZbMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Digits(mode='train')\n",
        "val_data = Digits(mode='val')\n",
        "test_data = Digits(mode='test')\n",
        "\n",
        "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "result_dir = 'results/'\n",
        "if not(os.path.exists(result_dir)):\n",
        "    os.mkdir(result_dir)\n",
        "name = 'realnvp'"
      ],
      "metadata": {
        "id": "10JuZkqHhfx1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "P727RHM0hgpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D = 64   # input dimension\n",
        "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
        "\n",
        "lr = 1e-3 # learning rate\n",
        "num_epochs = 1000 # max. number of epochs\n",
        "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
      ],
      "metadata": {
        "id": "MnddF7Jihok8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize RealNVP"
      ],
      "metadata": {
        "id": "vR954hjwhp5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of invertible transformations\n",
        "num_flows = 8\n",
        "\n",
        "# scale (s) network\n",
        "nets = lambda: nn.Sequential(nn.Linear(D // 2, M), nn.LeakyReLU(),\n",
        "                             nn.Linear(M, M), nn.LeakyReLU(),\n",
        "                             nn.Linear(M, D // 2), nn.Tanh())\n",
        "\n",
        "# translation (t) network\n",
        "nett = lambda: nn.Sequential(nn.Linear(D // 2, M), nn.LeakyReLU(),\n",
        "                             nn.Linear(M, M), nn.LeakyReLU(),\n",
        "                             nn.Linear(M, D // 2))\n",
        "\n",
        "# Prior (base distribution): Gaussian\n",
        "prior = torch.distributions.MultivariateNormal(torch.zeros(D), torch.eye(D))\n",
        "\n",
        "# Init RealNVP\n",
        "model = RealNVP(nets, nett, num_flows, prior, D=D, dequantization=True)"
      ],
      "metadata": {
        "id": "oS9riApqhzy9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ],
      "metadata": {
        "id": "KbWhTGzHiMYi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training procedure\n",
        "nll_val = training(name=result_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
        "                       training_loader=training_loader, val_loader=val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JZqwRmLiOVv",
        "outputId": "f898f3ee-eae4-4758-ff2e-1f921f604689"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll = 273.96423270089286\n",
            "Saved!\n",
            "Epoch: 1, val nll = 231.4692368861607\n",
            "Saved!\n",
            "Epoch: 2, val nll = 215.71248604910716\n",
            "Saved!\n",
            "Epoch: 3, val nll = 206.21343610491073\n",
            "Saved!\n",
            "Epoch: 4, val nll = 198.672529296875\n",
            "Saved!\n",
            "Epoch: 5, val nll = 192.53224051339285\n",
            "Saved!\n",
            "Epoch: 6, val nll = 187.20795200892857\n",
            "Saved!\n",
            "Epoch: 7, val nll = 182.743017578125\n",
            "Saved!\n",
            "Epoch: 8, val nll = 179.28142857142856\n",
            "Saved!\n",
            "Epoch: 9, val nll = 176.28331194196429\n",
            "Saved!\n",
            "Epoch: 10, val nll = 173.81815150669644\n",
            "Saved!\n",
            "Epoch: 11, val nll = 171.81197684151786\n",
            "Saved!\n",
            "Epoch: 12, val nll = 169.65369838169642\n",
            "Saved!\n",
            "Epoch: 13, val nll = 168.07443080357143\n",
            "Saved!\n",
            "Epoch: 14, val nll = 166.46301199776786\n",
            "Saved!\n",
            "Epoch: 15, val nll = 164.9895103236607\n",
            "Saved!\n",
            "Epoch: 16, val nll = 163.78516741071428\n",
            "Saved!\n",
            "Epoch: 17, val nll = 162.82151506696428\n",
            "Saved!\n",
            "Epoch: 18, val nll = 161.57569056919644\n",
            "Saved!\n",
            "Epoch: 19, val nll = 160.78778041294643\n",
            "Saved!\n",
            "Epoch: 20, val nll = 159.96385184151785\n",
            "Saved!\n",
            "Epoch: 21, val nll = 159.48517717633928\n",
            "Saved!\n",
            "Epoch: 22, val nll = 158.46675083705358\n",
            "Saved!\n",
            "Epoch: 23, val nll = 158.19791434151784\n",
            "Saved!\n",
            "Epoch: 24, val nll = 157.28489815848215\n",
            "Saved!\n",
            "Epoch: 25, val nll = 156.92032924107144\n",
            "Saved!\n",
            "Epoch: 26, val nll = 156.57135184151787\n",
            "Saved!\n",
            "Epoch: 27, val nll = 156.2545493861607\n",
            "Saved!\n",
            "Epoch: 28, val nll = 155.6245619419643\n",
            "Saved!\n",
            "Epoch: 29, val nll = 155.298115234375\n",
            "Saved!\n",
            "Epoch: 30, val nll = 154.60350306919642\n",
            "Saved!\n",
            "Epoch: 31, val nll = 154.01767578125\n",
            "Saved!\n",
            "Epoch: 32, val nll = 154.12352957589286\n",
            "Epoch: 33, val nll = 153.28954799107143\n",
            "Saved!\n",
            "Epoch: 34, val nll = 152.90876116071428\n",
            "Saved!\n",
            "Epoch: 35, val nll = 152.67108119419643\n",
            "Saved!\n",
            "Epoch: 36, val nll = 152.427587890625\n",
            "Saved!\n",
            "Epoch: 37, val nll = 152.4199009486607\n",
            "Saved!\n",
            "Epoch: 38, val nll = 152.39426897321428\n",
            "Saved!\n",
            "Epoch: 39, val nll = 151.61882393973215\n",
            "Saved!\n",
            "Epoch: 40, val nll = 151.7643959263393\n",
            "Epoch: 41, val nll = 151.70158761160715\n",
            "Epoch: 42, val nll = 151.5765638950893\n",
            "Saved!\n",
            "Epoch: 43, val nll = 151.32647879464287\n",
            "Saved!\n",
            "Epoch: 44, val nll = 152.34949358258928\n",
            "Epoch: 45, val nll = 151.339912109375\n",
            "Epoch: 46, val nll = 151.92139229910714\n",
            "Epoch: 47, val nll = 151.17935546875\n",
            "Saved!\n",
            "Epoch: 48, val nll = 152.51138811383927\n",
            "Epoch: 49, val nll = 151.47560546875\n",
            "Epoch: 50, val nll = 151.574287109375\n",
            "Epoch: 51, val nll = 151.9165931919643\n",
            "Epoch: 52, val nll = 152.35630301339285\n",
            "Epoch: 53, val nll = 151.19403459821427\n",
            "Epoch: 54, val nll = 152.12508091517856\n",
            "Epoch: 55, val nll = 151.39386021205357\n",
            "Epoch: 56, val nll = 152.19369838169644\n",
            "Epoch: 57, val nll = 153.35457728794643\n",
            "Epoch: 58, val nll = 153.30594866071428\n",
            "Epoch: 59, val nll = 152.79458984375\n",
            "Epoch: 60, val nll = 153.63811802455356\n",
            "Epoch: 61, val nll = 153.36633370535714\n",
            "Epoch: 62, val nll = 153.58551199776787\n",
            "Epoch: 63, val nll = 154.82933175223215\n",
            "Epoch: 64, val nll = 155.41786272321428\n",
            "Epoch: 65, val nll = 153.86978794642857\n",
            "Epoch: 66, val nll = 157.013623046875\n",
            "Epoch: 67, val nll = 154.189150390625\n",
            "Epoch: 68, val nll = 158.26309988839284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
        "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
        "f.write(str(test_loss))\n",
        "f.close()\n",
        "\n",
        "samples_real(result_dir + name, test_loader)\n",
        "\n",
        "plot_curve(result_dir + name, nll_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFJdszEpiTrk",
        "outputId": "2956f8cc-df4d-4f3b-b4aa-c4a1379dec09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Loss: nll = 140.4887575153803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-jypcBCXkfjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}